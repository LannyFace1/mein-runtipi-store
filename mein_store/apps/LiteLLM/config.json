{
  "id": "litellm",
  "name": "LiteLLM",
  "version": "main-latest",
  "description": "Ein Proxy-Server, der Ã¼ber 100 LLMs via OpenAI-API-Format konsolidiert.",
  "logo": "https://raw.githubusercontent.com/BerriAI/litellm/main/logo.png",
  "categories": ["AI", "LLM", "proxy"],
  "composeFile": "docker-compose.yml",
  "authors": ["BerriAI"],
  "source": "https://github.com/BerriAI/litellm",
  "documentation": "https://docs.litellm.ai/"
}
